{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST WGAN with feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aryopradiptagema/anaconda2/envs/kaggle/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-2-a42e6136b8fc>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/aryopradiptagema/anaconda2/envs/kaggle/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/aryopradiptagema/anaconda2/envs/kaggle/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:219: retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/aryopradiptagema/anaconda2/envs/kaggle/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/aryopradiptagema/anaconda2/envs/kaggle/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/aryopradiptagema/anaconda2/envs/kaggle/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ../../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ../../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/aryopradiptagema/anaconda2/envs/kaggle/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 1000\n",
    "h_dim = 128\n",
    "z_dim = 10\n",
    "image_dim = mnist.train.images.shape[1]\n",
    "target_dim = mnist.train.labels.shape[1]\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, h_dim, image_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.G = nn.Sequential(\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, image_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.G(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, h_dim, image_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.D = nn.Sequential(\n",
    "            nn.Linear(image_dim, h_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.out = nn.Linear(h_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feat = self.D(x)\n",
    "        out = self.out(feat)\n",
    "        return feat, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom JSD Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSDLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JSDLoss,self).__init__()\n",
    "\n",
    "    def forward(self, f_real, f_synt):\n",
    "        assert f_real.size()[1] == f_synt.size()[1]\n",
    "\n",
    "        f_num_features = f_real.size()[1]\n",
    "        batch_size = f_real.size()[0]\n",
    "        identity = autograd.Variable(torch.eye(f_num_features)*0.1)\n",
    "\n",
    "        if use_cuda:\n",
    "            identity = identity.cuda(gpu)\n",
    "\n",
    "        f_real_mean = torch.mean(f_real, 0, keepdim=True)\n",
    "        f_synt_mean = torch.mean(f_synt, 0, keepdim=True)\n",
    "\n",
    "        dev_f_real = f_real - f_real_mean.expand(batch_size,f_num_features) # batch_size x num_feat\n",
    "        dev_f_synt = f_synt - f_synt_mean.expand(batch_size,f_num_features) # batch_size x num_feat\n",
    "\n",
    "        f_real_xx = torch.mm(torch.t(dev_f_real), dev_f_real) # num_feat x batch_size * batch_size x num_feat = num_feat x num_feat\n",
    "        f_synt_xx = torch.mm(torch.t(dev_f_synt), dev_f_synt) # num_feat x batch_size * batch_size x num_feat = num_feat x num_feat\n",
    "\n",
    "        cov_mat_f_real = f_real_xx / (batch_size-1)# - torch.mm(f_real_mean, torch.t(f_real_mean)) + identity # num_feat x num_feat\n",
    "        cov_mat_f_synt = f_synt_xx / (batch_size-1)# - torch.mm(f_synt_mean, torch.t(f_synt_mean)) + identity # num_feat x num_feat\n",
    "\n",
    "        cov_mat_f_real_inv = torch.inverse(cov_mat_f_real)\n",
    "        cov_mat_f_synt_inv = torch.inverse(cov_mat_f_synt)\n",
    "\n",
    "        temp1 = torch.trace(torch.add(torch.mm(cov_mat_f_synt_inv, torch.t(cov_mat_f_real)), torch.mm(cov_mat_f_real_inv, torch.t(cov_mat_f_synt))))\n",
    "        temp1 = temp1.view(1,1)\n",
    "        temp2 = torch.mm(torch.mm((f_synt_mean - f_real_mean), (cov_mat_f_synt_inv + cov_mat_f_real_inv)), torch.t(f_synt_mean - f_real_mean))\n",
    "        loss_g = temp1 + temp2\n",
    "\n",
    "        return loss_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    G.zero_grad()\n",
    "    D.zero_grad()\n",
    "\n",
    "G = Generator(z_dim, h_dim, image_dim)\n",
    "D = Discriminator(h_dim, image_dim)\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=learning_rate)\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=learning_rate)\n",
    "jsdloss = JSDLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for _ in range(5):\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = True\n",
    "        \n",
    "        G.eval()\n",
    "        D.train()\n",
    "        z = Variable(torch.randn(batch_size, z_dim))\n",
    "        X, _ = mnist.train.next_batch(batch_size)\n",
    "        X = Variable(torch.from_numpy(X))\n",
    "\n",
    "        G_sample = G(z)\n",
    "        D_real_feat, D_real_out = D(X)\n",
    "        D_fake_feat, D_fake_out = D(G_sample)\n",
    "\n",
    "        D_loss_GAN = -(torch.mean(D_real_out) - torch.mean(D_fake_out))\n",
    "        D_loss_feat_matching = jsdloss(D_real_feat, D_fake_feat)\n",
    "        \n",
    "        D_loss = D_loss_GAN + D_loss_feat_matching\n",
    "\n",
    "        D_loss.backward()\n",
    "        D_solver.step()\n",
    "\n",
    "        for p in D.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "        reset_grad()\n",
    "    \n",
    "    for p in D.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    G.train()\n",
    "    D.eval()\n",
    "\n",
    "    X, _ = mnist.train.next_batch(batch_size)\n",
    "    X = Variable(torch.from_numpy(X))\n",
    "    z = Variable(torch.randn(batch_size, z_dim))\n",
    "\n",
    "    G_sample = G(z)\n",
    "    D_fake = D(G_sample)\n",
    "\n",
    "    G_loss = jsdloss(D_real_feat, D_fake_feat)\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_solver.step()\n",
    "\n",
    "    reset_grad()\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'\n",
    "              .format(epoch, D_loss.data.numpy(), G_loss.data.numpy()))\n",
    "\n",
    "        samples = G(z).data.numpy()[:16]\n",
    "\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        gs = gridspec.GridSpec(4, 4)\n",
    "        gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "        if not os.path.exists('out/'):\n",
    "            os.makedirs('out/')\n",
    "\n",
    "        plt.savefig('out/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        epoch += 1\n",
    "        plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data_translation/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n",
      "['elle est absorbee par son travail d etude .', 'she is absorbed in her study .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, BATCH_SIZE, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, BATCH_SIZE, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, BATCH_SIZE, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        encoder_outputs = encoder_outputs.permute(1,0,2)\n",
    "        embedded = self.embedding(input).view(1, BATCH_SIZE, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),\n",
    "                                 encoder_outputs)\n",
    "        attn_applied = attn_applied.permute(1,0,2)\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, BATCH_SIZE, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(indexes):\n",
    "    if len(indexes) == MAX_LENGTH:\n",
    "        return indexes\n",
    "    if len(indexes) < MAX_LENGTH:\n",
    "        indexes += [EOS_token]\n",
    "        return pad_sequence(indexes)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    indexes = pad_sequence(indexes)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_tensor = torch.cat([input_tensor_i.unsqueeze(0) for input_tensor_i in input_tensor], 0)\n",
    "    target_tensor = torch.cat([target_tensor_i.unsqueeze(0) for target_tensor_i in target_tensor], 0)\n",
    "\n",
    "    input_length = input_tensor.size(1)\n",
    "    target_length = target_tensor.size(1)\n",
    "    \n",
    "    input_tensor = input_tensor.permute(1,0,2)\n",
    "    target_tensor = target_tensor.permute(1,0,2)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, BATCH_SIZE, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]]*BATCH_SIZE, device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di].squeeze())\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            loss += criterion(decoder_output, target_tensor[di].squeeze())\n",
    "#             if decoder_input.item() == EOS_token:\n",
    "#                 break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[(iter-1)*BATCH_SIZE:iter*BATCH_SIZE] # n tensor (list)\n",
    "        input_tensor = [pair[0] for pair in training_pair]\n",
    "        target_tensor = [pair[1] for pair in training_pair]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 2s (- 3111m 27s) (1 0%) 8.0177\n",
      "0m 2s (- 1675m 4s) (2 0%) 7.8832\n",
      "0m 2s (- 1192m 51s) (3 0%) 7.7770\n",
      "0m 3s (- 949m 21s) (4 0%) 7.4672\n",
      "0m 3s (- 805m 57s) (5 0%) 6.6892\n",
      "0m 3s (- 708m 25s) (6 0%) 5.1975\n",
      "0m 3s (- 638m 19s) (7 0%) 5.1157\n",
      "0m 3s (- 584m 59s) (8 0%) 5.0370\n",
      "0m 3s (- 544m 22s) (9 0%) 4.7943\n",
      "0m 4s (- 510m 52s) (10 0%) 4.5980\n",
      "0m 4s (- 486m 38s) (11 0%) 4.2356\n",
      "0m 4s (- 468m 40s) (12 0%) 6.3739\n",
      "0m 4s (- 457m 24s) (13 0%) 4.6313\n",
      "0m 4s (- 445m 40s) (14 0%) 4.6576\n",
      "0m 5s (- 435m 37s) (15 0%) 4.4677\n",
      "0m 5s (- 425m 57s) (16 0%) 4.8185\n",
      "0m 5s (- 417m 24s) (17 0%) 5.0115\n",
      "0m 5s (- 406m 49s) (18 0%) 3.9247\n",
      "0m 6s (- 397m 46s) (19 0%) 5.0502\n",
      "0m 6s (- 388m 46s) (20 0%) 4.9980\n",
      "0m 6s (- 382m 13s) (21 0%) 4.3595\n",
      "0m 6s (- 376m 1s) (22 0%) 4.5264\n",
      "0m 6s (- 369m 51s) (23 0%) 4.1694\n",
      "0m 6s (- 364m 10s) (24 0%) 4.4730\n",
      "0m 7s (- 358m 55s) (25 0%) 3.9758\n",
      "0m 7s (- 353m 40s) (26 0%) 3.9034\n",
      "0m 7s (- 349m 36s) (27 0%) 4.0812\n",
      "0m 7s (- 344m 45s) (28 0%) 3.7683\n",
      "0m 7s (- 340m 32s) (29 0%) 3.7441\n",
      "0m 8s (- 336m 17s) (30 0%) 3.8478\n",
      "0m 8s (- 333m 0s) (31 0%) 3.6968\n",
      "0m 8s (- 329m 31s) (32 0%) 3.5246\n",
      "0m 8s (- 326m 38s) (33 0%) 3.8452\n",
      "0m 8s (- 323m 15s) (34 0%) 3.4475\n",
      "0m 8s (- 320m 42s) (35 0%) 3.4414\n",
      "0m 9s (- 318m 24s) (36 0%) 3.6076\n",
      "0m 9s (- 316m 22s) (37 0%) 3.4286\n",
      "0m 9s (- 313m 46s) (38 0%) 3.3052\n",
      "0m 9s (- 312m 3s) (39 0%) 3.5523\n",
      "0m 9s (- 312m 3s) (40 0%) 3.9330\n",
      "0m 10s (- 311m 39s) (41 0%) 3.9394\n",
      "0m 10s (- 309m 56s) (42 0%) 2.9565\n",
      "0m 10s (- 307m 58s) (43 0%) 3.3491\n",
      "0m 10s (- 305m 49s) (44 0%) 3.3643\n",
      "0m 10s (- 304m 33s) (45 0%) 3.7343\n",
      "0m 11s (- 303m 2s) (46 0%) 3.6617\n",
      "0m 11s (- 301m 50s) (47 0%) 3.5482\n",
      "0m 11s (- 300m 20s) (48 0%) 3.2963\n",
      "0m 11s (- 298m 40s) (49 0%) 2.8543\n",
      "0m 11s (- 296m 52s) (50 0%) 3.0753\n",
      "0m 12s (- 295m 33s) (51 0%) 3.5058\n",
      "0m 12s (- 294m 8s) (52 0%) 3.6282\n",
      "0m 12s (- 292m 53s) (53 0%) 3.1576\n",
      "0m 12s (- 291m 27s) (54 0%) 2.8447\n",
      "0m 12s (- 290m 12s) (55 0%) 3.5819\n",
      "0m 12s (- 288m 51s) (56 0%) 3.1590\n",
      "0m 13s (- 287m 51s) (57 0%) 3.2602\n",
      "0m 13s (- 286m 31s) (58 0%) 3.4221\n",
      "0m 13s (- 285m 27s) (59 0%) 3.3975\n",
      "0m 13s (- 284m 18s) (60 0%) 3.1624\n",
      "0m 13s (- 283m 47s) (61 0%) 3.4940\n",
      "0m 14s (- 282m 39s) (62 0%) 3.0913\n",
      "0m 14s (- 281m 52s) (63 0%) 4.0208\n",
      "0m 14s (- 280m 47s) (64 0%) 3.1635\n",
      "0m 14s (- 280m 7s) (65 0%) 3.7225\n",
      "0m 14s (- 279m 10s) (66 0%) 3.2908\n",
      "0m 14s (- 278m 37s) (67 0%) 3.0201\n",
      "0m 15s (- 277m 58s) (68 0%) 3.2880\n",
      "0m 15s (- 277m 9s) (69 0%) 3.4718\n",
      "0m 15s (- 276m 21s) (70 0%) 3.3240\n",
      "0m 15s (- 275m 43s) (71 0%) 3.1611\n",
      "0m 15s (- 275m 11s) (72 0%) 3.0284\n",
      "0m 16s (- 274m 57s) (73 0%) 2.8797\n",
      "0m 16s (- 274m 59s) (74 0%) 3.5218\n",
      "0m 16s (- 274m 45s) (75 0%) 3.1304\n",
      "0m 16s (- 274m 13s) (76 0%) 2.7878\n",
      "0m 16s (- 273m 39s) (77 0%) 2.9650\n",
      "0m 17s (- 273m 18s) (78 0%) 3.5578\n",
      "0m 17s (- 273m 8s) (79 0%) 2.9680\n",
      "0m 17s (- 273m 25s) (80 0%) 3.1652\n",
      "0m 17s (- 273m 2s) (81 0%) 3.0047\n",
      "0m 17s (- 272m 58s) (82 0%) 3.1636\n",
      "0m 18s (- 272m 57s) (83 0%) 3.1276\n",
      "0m 18s (- 273m 31s) (84 0%) 3.0617\n",
      "0m 18s (- 273m 37s) (85 0%) 2.9711\n",
      "0m 18s (- 273m 30s) (86 0%) 2.9424\n",
      "0m 19s (- 273m 26s) (87 0%) 2.9853\n",
      "0m 19s (- 273m 0s) (88 0%) 3.0400\n",
      "0m 19s (- 272m 39s) (89 0%) 2.8684\n",
      "0m 19s (- 272m 13s) (90 0%) 3.0454\n",
      "0m 19s (- 271m 45s) (91 0%) 2.8799\n",
      "0m 19s (- 271m 10s) (92 0%) 3.0004\n",
      "0m 20s (- 270m 46s) (93 0%) 3.0164\n",
      "0m 20s (- 270m 17s) (94 0%) 3.5169\n",
      "0m 20s (- 270m 10s) (95 0%) 3.0564\n",
      "0m 20s (- 269m 42s) (96 0%) 2.9835\n",
      "0m 20s (- 269m 29s) (97 0%) 3.1914\n",
      "0m 21s (- 269m 6s) (98 0%) 3.2277\n",
      "0m 21s (- 268m 42s) (99 0%) 2.8128\n",
      "0m 21s (- 268m 9s) (100 0%) 2.6990\n",
      "0m 21s (- 267m 52s) (101 0%) 3.1597\n",
      "0m 21s (- 267m 32s) (102 0%) 2.8048\n",
      "0m 22s (- 267m 12s) (103 0%) 2.8783\n",
      "0m 22s (- 266m 50s) (104 0%) 3.2948\n",
      "0m 22s (- 266m 27s) (105 0%) 3.1180\n",
      "0m 22s (- 266m 2s) (106 0%) 3.0168\n",
      "0m 22s (- 265m 41s) (107 0%) 3.2408\n",
      "0m 22s (- 265m 12s) (108 0%) 2.6315\n",
      "0m 23s (- 264m 55s) (109 0%) 3.4754\n",
      "0m 23s (- 264m 25s) (110 0%) 3.3782\n",
      "0m 23s (- 264m 2s) (111 0%) 2.7525\n",
      "0m 23s (- 263m 38s) (112 0%) 2.9397\n",
      "0m 23s (- 263m 16s) (113 0%) 2.7360\n",
      "0m 24s (- 262m 58s) (114 0%) 2.8843\n",
      "0m 24s (- 262m 40s) (115 0%) 2.6125\n",
      "0m 24s (- 262m 17s) (116 0%) 2.6904\n",
      "0m 24s (- 262m 4s) (117 0%) 3.0633\n",
      "0m 24s (- 261m 41s) (118 0%) 2.9196\n",
      "0m 24s (- 261m 33s) (119 0%) 2.5329\n",
      "0m 25s (- 261m 21s) (120 0%) 2.9849\n",
      "0m 25s (- 261m 10s) (121 0%) 3.0488\n",
      "0m 25s (- 260m 52s) (122 0%) 2.9701\n",
      "0m 25s (- 260m 38s) (123 0%) 2.9177\n",
      "0m 25s (- 260m 23s) (124 0%) 2.8841\n",
      "0m 26s (- 260m 6s) (125 0%) 2.7251\n",
      "0m 26s (- 259m 51s) (126 0%) 2.6391\n",
      "0m 26s (- 259m 40s) (127 0%) 2.7828\n",
      "0m 26s (- 259m 21s) (128 0%) 2.5316\n",
      "0m 26s (- 259m 7s) (129 0%) 3.0886\n",
      "0m 26s (- 258m 51s) (130 0%) 2.7132\n",
      "0m 27s (- 258m 42s) (131 0%) 2.8746\n",
      "0m 27s (- 258m 24s) (132 0%) 3.0024\n",
      "0m 27s (- 258m 18s) (133 0%) 2.8215\n",
      "0m 27s (- 258m 6s) (134 0%) 2.7183\n",
      "0m 27s (- 258m 1s) (135 0%) 3.2072\n",
      "0m 28s (- 257m 43s) (136 0%) 2.6328\n",
      "0m 28s (- 257m 33s) (137 0%) 2.9177\n",
      "0m 28s (- 257m 14s) (138 0%) 2.9292\n",
      "0m 28s (- 257m 0s) (139 0%) 2.9659\n",
      "0m 28s (- 256m 45s) (140 0%) 2.9618\n",
      "0m 28s (- 256m 35s) (141 0%) 3.0330\n",
      "0m 29s (- 256m 17s) (142 0%) 2.8776\n",
      "0m 29s (- 256m 2s) (143 0%) 2.5582\n",
      "0m 29s (- 255m 44s) (144 0%) 2.9648\n",
      "0m 29s (- 255m 33s) (145 0%) 2.6417\n",
      "0m 29s (- 255m 23s) (146 0%) 2.6491\n",
      "0m 30s (- 255m 16s) (147 0%) 2.8264\n",
      "0m 30s (- 255m 3s) (148 0%) 2.5529\n",
      "0m 30s (- 254m 51s) (149 0%) 2.5091\n",
      "0m 30s (- 254m 39s) (150 0%) 3.1237\n",
      "0m 30s (- 254m 29s) (151 0%) 2.6096\n",
      "0m 30s (- 254m 17s) (152 0%) 3.0453\n",
      "0m 31s (- 254m 10s) (153 0%) 2.6147\n",
      "0m 31s (- 253m 57s) (154 0%) 2.6433\n",
      "0m 31s (- 253m 48s) (155 0%) 2.3770\n",
      "0m 31s (- 253m 42s) (156 0%) 2.9176\n",
      "0m 31s (- 253m 35s) (157 0%) 2.8184\n",
      "0m 32s (- 253m 23s) (158 0%) 2.7027\n",
      "0m 32s (- 253m 14s) (159 0%) 2.6958\n",
      "0m 32s (- 253m 2s) (160 0%) 3.1220\n",
      "0m 32s (- 252m 48s) (161 0%) 2.3709\n",
      "0m 32s (- 252m 32s) (162 0%) 2.4087\n",
      "0m 32s (- 252m 21s) (163 0%) 2.4577\n",
      "0m 33s (- 252m 10s) (164 0%) 2.8833\n",
      "0m 33s (- 251m 57s) (165 0%) 2.5906\n",
      "0m 33s (- 251m 45s) (166 0%) 2.8533\n",
      "0m 33s (- 251m 38s) (167 0%) 2.9056\n",
      "0m 33s (- 251m 34s) (168 0%) 2.8031\n",
      "0m 34s (- 251m 30s) (169 0%) 2.9891\n",
      "0m 34s (- 251m 23s) (170 0%) 3.0135\n",
      "0m 34s (- 251m 15s) (171 0%) 2.5771\n",
      "0m 34s (- 251m 6s) (172 0%) 2.6581\n",
      "0m 34s (- 250m 58s) (173 0%) 2.6656\n",
      "0m 34s (- 250m 47s) (174 0%) 2.6212\n",
      "0m 35s (- 250m 38s) (175 0%) 2.6946\n",
      "0m 35s (- 250m 26s) (176 0%) 3.1020\n",
      "0m 35s (- 250m 23s) (177 0%) 3.2306\n",
      "0m 35s (- 250m 13s) (178 0%) 2.8126\n",
      "0m 35s (- 250m 3s) (179 0%) 2.5252\n",
      "0m 36s (- 249m 55s) (180 0%) 2.7175\n",
      "0m 36s (- 249m 53s) (181 0%) 2.5960\n",
      "0m 36s (- 249m 43s) (182 0%) 2.7787\n",
      "0m 36s (- 249m 37s) (183 0%) 2.7456\n",
      "0m 36s (- 249m 29s) (184 0%) 2.5606\n",
      "0m 37s (- 249m 25s) (185 0%) 2.2968\n",
      "0m 37s (- 249m 17s) (186 0%) 2.3822\n",
      "0m 37s (- 249m 15s) (187 0%) 2.4690\n",
      "0m 37s (- 249m 6s) (188 0%) 3.4230\n",
      "0m 37s (- 249m 0s) (189 0%) 2.8079\n",
      "0m 37s (- 248m 54s) (190 0%) 3.0496\n",
      "0m 38s (- 248m 49s) (191 0%) 2.8684\n",
      "0m 38s (- 248m 42s) (192 0%) 2.9160\n",
      "0m 38s (- 248m 34s) (193 0%) 2.5778\n",
      "0m 38s (- 248m 23s) (194 0%) 2.5072\n",
      "0m 38s (- 248m 19s) (195 0%) 2.5273\n",
      "0m 39s (- 248m 18s) (196 0%) 2.5593\n",
      "0m 39s (- 248m 19s) (197 0%) 3.0980\n",
      "0m 39s (- 248m 10s) (198 0%) 2.5646\n",
      "0m 39s (- 248m 2s) (199 0%) 2.5185\n",
      "0m 39s (- 247m 52s) (200 0%) 2.8293\n",
      "0m 39s (- 247m 46s) (201 0%) 2.5060\n",
      "0m 40s (- 247m 38s) (202 0%) 2.7400\n",
      "0m 40s (- 247m 30s) (203 0%) 2.5465\n",
      "0m 40s (- 247m 17s) (204 0%) 2.4798\n",
      "0m 40s (- 247m 11s) (205 0%) 2.7648\n",
      "0m 40s (- 247m 2s) (206 0%) 2.9995\n",
      "0m 40s (- 246m 53s) (207 0%) 2.4677\n",
      "0m 41s (- 246m 45s) (208 0%) 2.7451\n",
      "0m 41s (- 246m 39s) (209 0%) 2.6680\n",
      "0m 41s (- 246m 42s) (210 0%) 2.7259\n",
      "0m 41s (- 246m 35s) (211 0%) 2.5701\n",
      "0m 41s (- 246m 27s) (212 0%) 2.6633\n",
      "0m 42s (- 246m 20s) (213 0%) 3.0503\n",
      "0m 42s (- 246m 13s) (214 0%) 2.7036\n",
      "0m 42s (- 246m 6s) (215 0%) 2.8938\n",
      "0m 42s (- 245m 58s) (216 0%) 2.4362\n",
      "0m 42s (- 245m 49s) (217 0%) 2.5375\n",
      "0m 42s (- 245m 44s) (218 0%) 2.6174\n",
      "0m 43s (- 245m 38s) (219 0%) 2.5713\n",
      "0m 43s (- 245m 33s) (220 0%) 2.8167\n",
      "0m 43s (- 245m 24s) (221 0%) 2.7528\n",
      "0m 43s (- 245m 20s) (222 0%) 2.7737\n",
      "0m 43s (- 245m 14s) (223 0%) 2.8957\n",
      "0m 44s (- 245m 9s) (224 0%) 2.5068\n",
      "0m 44s (- 245m 2s) (225 0%) 2.8521\n",
      "0m 44s (- 244m 56s) (226 0%) 2.6322\n",
      "0m 44s (- 244m 50s) (227 0%) 2.6344\n",
      "0m 44s (- 244m 44s) (228 0%) 2.3849\n",
      "0m 44s (- 244m 49s) (229 0%) 2.8087\n",
      "0m 45s (- 244m 59s) (230 0%) 2.9312\n",
      "0m 45s (- 245m 7s) (231 0%) 2.8384\n",
      "0m 45s (- 245m 11s) (232 0%) 2.7170\n",
      "0m 45s (- 245m 28s) (233 0%) 2.7203\n",
      "0m 46s (- 245m 28s) (234 0%) 2.4949\n",
      "0m 46s (- 245m 26s) (235 0%) 2.4503\n",
      "0m 46s (- 245m 39s) (236 0%) 2.4402\n",
      "0m 46s (- 245m 50s) (237 0%) 2.4967\n",
      "0m 46s (- 245m 50s) (238 0%) 2.3733\n",
      "0m 47s (- 245m 48s) (239 0%) 2.3045\n",
      "0m 47s (- 245m 51s) (240 0%) 2.9560\n",
      "0m 47s (- 245m 58s) (241 0%) 2.7004\n",
      "0m 47s (- 245m 53s) (242 0%) 2.0660\n",
      "0m 47s (- 245m 54s) (243 0%) 3.3021\n",
      "0m 48s (- 245m 59s) (244 0%) 2.9270\n",
      "0m 48s (- 245m 55s) (245 0%) 2.3293\n",
      "0m 48s (- 245m 51s) (246 0%) 2.3687\n",
      "0m 48s (- 245m 46s) (247 0%) 3.2554\n",
      "0m 48s (- 245m 42s) (248 0%) 2.9864\n",
      "0m 49s (- 245m 38s) (249 0%) 2.6122\n",
      "0m 49s (- 245m 44s) (250 0%) 2.7036\n",
      "0m 49s (- 245m 44s) (251 0%) 2.3593\n",
      "0m 49s (- 245m 56s) (252 0%) 2.3529\n",
      "0m 50s (- 246m 19s) (253 0%) 2.9589\n",
      "0m 50s (- 246m 24s) (254 0%) 2.8253\n",
      "0m 50s (- 246m 24s) (255 0%) 2.7051\n",
      "0m 50s (- 246m 36s) (256 0%) 2.7647\n",
      "0m 50s (- 246m 32s) (257 0%) 2.6735\n",
      "0m 51s (- 246m 27s) (258 0%) 2.7054\n",
      "0m 51s (- 246m 19s) (259 0%) 2.6045\n",
      "0m 51s (- 246m 25s) (260 0%) 2.8829\n",
      "0m 51s (- 246m 18s) (261 0%) 2.5887\n",
      "0m 51s (- 246m 14s) (262 0%) 2.5191\n",
      "0m 51s (- 246m 8s) (263 0%) 2.3792\n",
      "0m 52s (- 246m 5s) (264 0%) 2.7609\n",
      "0m 52s (- 245m 59s) (265 0%) 2.3640\n",
      "0m 52s (- 245m 56s) (266 0%) 2.3447\n",
      "0m 52s (- 245m 50s) (267 0%) 2.1324\n",
      "0m 52s (- 245m 51s) (268 0%) 2.5743\n",
      "0m 53s (- 245m 54s) (269 0%) 2.5121\n",
      "0m 53s (- 246m 0s) (270 0%) 2.6320\n",
      "0m 53s (- 246m 3s) (271 0%) 2.5922\n",
      "0m 53s (- 246m 4s) (272 0%) 2.6921\n",
      "0m 53s (- 246m 1s) (273 0%) 2.7278\n",
      "0m 54s (- 245m 56s) (274 0%) 2.7460\n",
      "0m 54s (- 245m 58s) (275 0%) 2.3078\n",
      "0m 54s (- 245m 57s) (276 0%) 2.6581\n",
      "0m 54s (- 245m 57s) (277 0%) 2.3228\n",
      "0m 54s (- 245m 52s) (278 0%) 2.6221\n",
      "0m 55s (- 245m 50s) (279 0%) 2.5536\n",
      "0m 55s (- 245m 43s) (280 0%) 2.2620\n",
      "0m 55s (- 245m 40s) (281 0%) 2.9483\n",
      "0m 55s (- 245m 33s) (282 0%) 2.4378\n",
      "0m 55s (- 245m 28s) (283 0%) 2.3341\n",
      "0m 55s (- 245m 24s) (284 0%) 2.6572\n",
      "0m 56s (- 245m 27s) (285 0%) 2.5142\n",
      "0m 56s (- 245m 24s) (286 0%) 2.3214\n",
      "0m 56s (- 245m 22s) (287 0%) 2.3722\n",
      "0m 56s (- 245m 16s) (288 0%) 2.4622\n",
      "0m 56s (- 245m 13s) (289 0%) 2.3446\n",
      "0m 57s (- 245m 12s) (290 0%) 2.7396\n",
      "0m 57s (- 245m 14s) (291 0%) 2.5004\n",
      "0m 57s (- 245m 26s) (292 0%) 2.5946\n",
      "0m 57s (- 245m 35s) (293 0%) 3.3118\n",
      "0m 58s (- 245m 45s) (294 0%) 3.4371\n",
      "0m 58s (- 245m 50s) (295 0%) 2.7428\n",
      "0m 58s (- 245m 54s) (296 0%) 2.2418\n",
      "0m 58s (- 246m 0s) (297 0%) 3.0577\n",
      "0m 58s (- 245m 55s) (298 0%) 2.5354\n",
      "0m 59s (- 245m 52s) (299 0%) 2.5732\n",
      "0m 59s (- 245m 49s) (300 0%) 2.4747\n",
      "0m 59s (- 245m 53s) (301 0%) 2.4962\n",
      "0m 59s (- 245m 52s) (302 0%) 2.8306\n",
      "0m 59s (- 245m 51s) (303 0%) 2.8177\n",
      "1m 0s (- 245m 45s) (304 0%) 2.1567\n",
      "1m 0s (- 245m 42s) (305 0%) 2.4679\n",
      "1m 0s (- 245m 39s) (306 0%) 2.5611\n",
      "1m 0s (- 245m 36s) (307 0%) 2.9091\n",
      "1m 0s (- 245m 32s) (308 0%) 2.4037\n",
      "1m 0s (- 245m 30s) (309 0%) 2.6764\n",
      "1m 1s (- 245m 24s) (310 0%) 2.2243\n",
      "1m 1s (- 245m 22s) (311 0%) 2.3958\n",
      "1m 1s (- 245m 16s) (312 0%) 2.4872\n",
      "1m 1s (- 245m 12s) (313 0%) 2.3991\n",
      "1m 1s (- 245m 7s) (314 0%) 2.3778\n",
      "1m 2s (- 245m 7s) (315 0%) 2.9393\n",
      "1m 2s (- 245m 4s) (316 0%) 2.8046\n",
      "1m 2s (- 245m 2s) (317 0%) 2.2018\n",
      "1m 2s (- 244m 56s) (318 0%) 2.2997\n",
      "1m 2s (- 244m 53s) (319 0%) 2.6397\n",
      "1m 2s (- 244m 49s) (320 0%) 2.4826\n",
      "1m 3s (- 244m 46s) (321 0%) 2.5393\n",
      "1m 3s (- 244m 40s) (322 0%) 2.0818\n",
      "1m 3s (- 244m 37s) (323 0%) 2.8353\n",
      "1m 3s (- 244m 34s) (324 0%) 2.7516\n",
      "1m 3s (- 244m 30s) (325 0%) 2.4519\n",
      "1m 4s (- 244m 26s) (326 0%) 2.5244\n",
      "1m 4s (- 244m 26s) (327 0%) 2.6426\n",
      "1m 4s (- 244m 22s) (328 0%) 2.6182\n",
      "1m 4s (- 244m 22s) (329 0%) 2.7483\n",
      "1m 4s (- 244m 18s) (330 0%) 2.8647\n",
      "1m 4s (- 244m 20s) (331 0%) 3.0005\n",
      "1m 5s (- 244m 19s) (332 0%) 2.5015\n",
      "1m 5s (- 244m 18s) (333 0%) 3.0101\n",
      "1m 5s (- 244m 12s) (334 0%) 2.6142\n",
      "1m 5s (- 244m 8s) (335 0%) 2.1074\n",
      "1m 5s (- 244m 4s) (336 0%) 2.5408\n",
      "1m 6s (- 244m 1s) (337 0%) 2.4609\n",
      "1m 6s (- 243m 55s) (338 0%) 2.2247\n",
      "1m 6s (- 244m 0s) (339 0%) 2.7975\n",
      "1m 6s (- 243m 58s) (340 0%) 2.3485\n",
      "1m 6s (- 243m 56s) (341 0%) 3.0991\n",
      "1m 7s (- 243m 50s) (342 0%) 2.7013\n",
      "1m 7s (- 243m 46s) (343 0%) 2.3061\n",
      "1m 7s (- 243m 43s) (344 0%) 2.5136\n",
      "1m 7s (- 243m 38s) (345 0%) 2.4016\n",
      "1m 7s (- 243m 35s) (346 0%) 2.9600\n",
      "1m 7s (- 243m 32s) (347 0%) 3.0398\n",
      "1m 8s (- 243m 28s) (348 0%) 2.9397\n",
      "1m 8s (- 243m 27s) (349 0%) 2.8862\n",
      "1m 8s (- 243m 24s) (350 0%) 2.7606\n",
      "1m 8s (- 243m 22s) (351 0%) 2.9166\n",
      "1m 8s (- 243m 17s) (352 0%) 2.6747\n",
      "1m 9s (- 243m 21s) (353 0%) 2.2689\n",
      "1m 9s (- 243m 25s) (354 0%) 2.4713\n",
      "1m 9s (- 243m 24s) (355 0%) 2.1966\n",
      "1m 9s (- 243m 25s) (356 0%) 2.3271\n",
      "1m 9s (- 243m 30s) (357 0%) 2.4724\n",
      "1m 10s (- 243m 37s) (358 0%) 2.1060\n",
      "1m 10s (- 243m 40s) (359 0%) 2.6832\n",
      "1m 10s (- 243m 37s) (360 0%) 2.7425\n",
      "1m 10s (- 243m 35s) (361 0%) 2.6583\n",
      "1m 10s (- 243m 34s) (362 0%) 2.2961\n",
      "1m 11s (- 243m 32s) (363 0%) 2.3082\n",
      "1m 11s (- 243m 34s) (364 0%) 2.7155\n",
      "1m 11s (- 243m 43s) (365 0%) 2.7278\n",
      "1m 11s (- 243m 45s) (366 0%) 2.4235\n",
      "1m 11s (- 243m 46s) (367 0%) 2.8382\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-333-d286c7a856fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-329-26ed9d4f1aaa>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m---> 19\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-327-7db7cf0a96fa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             decoder_output, decoder_hidden, decoder_attention = decoder(\n\u001b[0;32m---> 38\u001b[0;31m                 decoder_input, decoder_hidden, encoder_outputs)\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Teacher forcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/kaggle/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-269-ed0233c8fc69>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/kaggle/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/kaggle/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/kaggle/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
